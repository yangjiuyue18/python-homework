{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torchviz\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Операции с тензорами\n",
    "\n",
    "Базовые операции с тензорами похожи на NumPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, dtype=torch.float32)\n",
    "y = torch.tensor([1.0, 2.0, 3.0])\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140209489579200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140209489579200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x += 2\n",
    "id(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2)\n",
    "y = torch.zeros(2, 2)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1324, -0.5336, -0.1154],\n",
       "        [ 0.5291,  2.5885,  1.3315]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1120],\n",
       "        [ 0.2209],\n",
       "        [ 0.8513],\n",
       "        [-0.4273],\n",
       "        [-0.6676],\n",
       "        [-2.2599]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3).view((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важным момент - поддержка CUDA. Существует абстракция `device` - устройство на котором будут произоводиться вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "cpu = torch.device('cpu')   \n",
    "# cuda = torch.device('cuda')     \n",
    "# cuda0 = torch.device('cuda:0')\n",
    "# cuda1 = torch.device('cuda:1') \n",
    "# torch.set_default_tensor_type\n",
    "\n",
    "x = torch.tensor([1., 2.], device=cpu)\n",
    "# y = torch.tensor([1., 2.]).cuda()\n",
    "# z = torch.tensor([1., 2.]).cpu()\n",
    "# z = torch.tensor([1., 2.]).to(cuda)\n",
    "\n",
    "# with torch.cuda.device(1):\n",
    "#     x = torch.tensor([1., 2.], device=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоматическое дифференцировние"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда при создании тензора указывается параметр `requires_grad`, PyTorch запоминает все операции с тензором, чтобы потом можно было вычислить градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.) tensor(2.)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"289pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 289.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 285,-387 285,4 -4,4\"/>\n<!-- 140209482685856 -->\n<g id=\"node1\" class=\"node\">\n<title>140209482685856</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140209477172912 -->\n<g id=\"node2\" class=\"node\">\n<title>140209477172912</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-86 59,-86 59,-67 148,-67 148,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140209477172912&#45;&gt;140209482685856 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140209477172912&#45;&gt;140209482685856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n</g>\n<!-- 140209477172096 -->\n<g id=\"node3\" class=\"node\">\n<title>140209477172096</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"202,-141 113,-141 113,-122 202,-122 202,-141\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140209477172096&#45;&gt;140209477172912 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140209477172096&#45;&gt;140209477172912</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.58,-121.75C140.72,-114.03 129.07,-102.6 119.58,-93.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-90.6 112.25,-86.09 116.94,-95.59 121.84,-90.6\"/>\n</g>\n<!-- 140209477172384 -->\n<g id=\"node4\" class=\"node\">\n<title>140209477172384</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"281,-196 192,-196 192,-177 281,-177 281,-196\"/>\n<text text-anchor=\"middle\" x=\"236.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140209477172384&#45;&gt;140209477172096 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140209477172384&#45;&gt;140209477172096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M223.81,-176.98C211.67,-168.84 193.14,-156.41 178.75,-146.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"180.68,-143.84 170.42,-141.17 176.78,-149.65 180.68,-143.84\"/>\n</g>\n<!-- 140209483156496 -->\n<g id=\"node5\" class=\"node\">\n<title>140209483156496</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"250,-311.5 149,-311.5 149,-292.5 250,-292.5 250,-311.5\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140209483156496&#45;&gt;140209477172384 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140209483156496&#45;&gt;140209477172384</title>\n<path fill=\"none\" stroke=\"black\" d=\"M202.83,-292.2C206.56,-282.25 212.71,-265.55 217.5,-251 222.46,-235.95 227.58,-218.73 231.25,-206.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"234.68,-206.75 234.07,-196.17 227.95,-204.82 234.68,-206.75\"/>\n</g>\n<!-- 140209483159952 -->\n<g id=\"node8\" class=\"node\">\n<title>140209483159952</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-251 119,-251 119,-232 208,-232 208,-251\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140209483156496&#45;&gt;140209483159952 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140209483156496&#45;&gt;140209483159952</title>\n<path fill=\"none\" stroke=\"black\" d=\"M194.19,-292.37C188.92,-283.81 180.71,-270.47 174.11,-259.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"177.06,-257.85 168.83,-251.17 171.09,-261.52 177.06,-257.85\"/>\n</g>\n<!-- 140209484181840 -->\n<g id=\"node6\" class=\"node\">\n<title>140209484181840</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"226.5,-383 172.5,-383 172.5,-353 226.5,-353 226.5,-383\"/>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n<text text-anchor=\"middle\" x=\"199.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140209484181840&#45;&gt;140209483156496 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140209484181840&#45;&gt;140209483156496</title>\n<path fill=\"none\" stroke=\"black\" d=\"M199.5,-352.8C199.5,-343.7 199.5,-331.79 199.5,-321.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"203,-321.84 199.5,-311.84 196,-321.84 203,-321.84\"/>\n</g>\n<!-- 140209477173104 -->\n<g id=\"node7\" class=\"node\">\n<title>140209477173104</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"174,-196 85,-196 85,-177 174,-177 174,-196\"/>\n<text text-anchor=\"middle\" x=\"129.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140209477173104&#45;&gt;140209477172096 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140209477173104&#45;&gt;140209477172096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M134.12,-176.75C137.96,-169.49 143.52,-158.95 148.26,-149.98\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"151.39,-151.57 152.96,-141.09 145.2,-148.3 151.39,-151.57\"/>\n</g>\n<!-- 140209483159952&#45;&gt;140209477173104 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140209483159952&#45;&gt;140209477173104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.89,-231.75C153.18,-224.42 146.33,-213.73 140.53,-204.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.36,-202.62 135.01,-196.09 137.46,-206.4 143.36,-202.62\"/>\n</g>\n<!-- 140209483159808 -->\n<g id=\"node9\" class=\"node\">\n<title>140209483159808</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140209483159808&#45;&gt;140209477173104 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140209483159808&#45;&gt;140209477173104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.19,-231.98C75.33,-223.84 93.86,-211.41 108.25,-201.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110.22,-204.65 116.58,-196.17 106.32,-198.84 110.22,-204.65\"/>\n</g>\n<!-- 140209477167920 -->\n<g id=\"node11\" class=\"node\">\n<title>140209477167920</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140209483159808&#45;&gt;140209477167920 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140209483159808&#45;&gt;140209477167920</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.66C50.5,-214.17 50.5,-174.8 50.5,-151.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.16 50.5,-141.16 47,-151.16 54,-151.16\"/>\n</g>\n<!-- 140209482894608 -->\n<g id=\"node10\" class=\"node\">\n<title>140209482894608</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-317 23.5,-317 23.5,-287 77.5,-287 77.5,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">y</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140209482894608&#45;&gt;140209483159808 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140209482894608&#45;&gt;140209483159808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n</g>\n<!-- 140209477167920&#45;&gt;140209477172912 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140209477167920&#45;&gt;140209477172912</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.25,-121.75C66.97,-114.03 78.4,-102.6 87.72,-93.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-95.64 94.91,-86.09 85.36,-90.69 90.31,-95.64\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f8510b85810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "val = x ** 2 - 2 * x * y + y ** 2\n",
    "val.backward()\n",
    "\n",
    "print(x.grad, y.grad)\n",
    "\n",
    "torchviz.make_dot(val, {'x': x, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"101pt\" height=\"213pt\"\n viewBox=\"0.00 0.00 101.00 213.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 209)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-209 97,-209 97,4 -4,4\"/>\n<!-- 139653973726152 -->\n<g id=\"node1\" class=\"node\">\n<title>139653973726152</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"93,-21 0,-21 0,0 93,0 93,-21\"/>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SumBackward0</text>\n</g>\n<!-- 139653973726096 -->\n<g id=\"node2\" class=\"node\">\n<title>139653973726096</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"92.5,-78 .5,-78 .5,-57 92.5,-57 92.5,-78\"/>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139653973726096&#45;&gt;139653973726152 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139653973726096&#45;&gt;139653973726152</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M46.5,-56.7787C46.5,-49.6134 46.5,-39.9517 46.5,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"50.0001,-31.1732 46.5,-21.1732 43.0001,-31.1732 50.0001,-31.1732\"/>\n</g>\n<!-- 139653973726320 -->\n<g id=\"node3\" class=\"node\">\n<title>139653973726320</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"92,-135 1,-135 1,-114 92,-114 92,-135\"/>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139653973726320&#45;&gt;139653973726096 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139653973726320&#45;&gt;139653973726096</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M46.5,-113.7787C46.5,-106.6134 46.5,-96.9517 46.5,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"50.0001,-88.1732 46.5,-78.1732 43.0001,-88.1732 50.0001,-88.1732\"/>\n</g>\n<!-- 139653973726488 -->\n<g id=\"node4\" class=\"node\">\n<title>139653973726488</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"73.5,-205 19.5,-205 19.5,-171 73.5,-171 73.5,-205\"/>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">a</text>\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (3)</text>\n</g>\n<!-- 139653973726488&#45;&gt;139653973726320 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139653973726488&#45;&gt;139653973726320</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M46.5,-170.9832C46.5,-163.1157 46.5,-153.6973 46.5,-145.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"50.0001,-145.3686 46.5,-135.3687 43.0001,-145.3687 50.0001,-145.3686\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f03b97ed048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3.], requires_grad=True) \n",
    "b = (5 * a + 2).sum()\n",
    "\n",
    "torchviz.make_dot(b, {'a': a})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем наивный градиентный спуск для функции $f(x) = x^2 - 2x + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2., requires_grad=True)\n",
    "lr = 1e-2\n",
    "\n",
    "for i in range(500):\n",
    "    val = x ** 2 - 2 * x + 1\n",
    "    val.backward()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        x -= lr * x.grad\n",
    "    \n",
    "    x.grad.zero_()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сгенерируем тренировочное, тестовое и валидационное множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "    def __init__(self,  \n",
    "            n=3, \n",
    "            a=[1.2, 3.0, -1.5],\n",
    "            b=[25]):                \n",
    "        \n",
    "        self.n = 3        \n",
    "        self.a = np.array(a).reshape((1, -1))\n",
    "        self.b = np.array(b).reshape((1, -1))\n",
    "        \n",
    "    def gen_Xy(self, count=50):\n",
    "        a, b = self.a, self.b\n",
    "        \n",
    "        noise = np.random.normal(0., 1., size=(count, 1))\n",
    "        X = np.random.uniform(-30.0, 30.0, size=(count, self.n))\n",
    "        y = X @ a.T + self.b + noise\n",
    "        \n",
    "        return X, y\n",
    "        \n",
    "    def gen_Xy_torch(self, count=50, device='cpu'):\n",
    "        X, y = self.gen_Xy(count)\n",
    "        return [torch.tensor(t, dtype=torch.float, device=device) for t in (X, y) ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, l, t, v = 3, 300, 50, 10\n",
    "dg = DataGen(n=n)\n",
    "\n",
    "X_train, y_train = dg.gen_Xy_torch(l)\n",
    "X_test, y_test = dg.gen_Xy_torch(t)\n",
    "X_val, y_val = dg.gen_Xy_torch(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 14.7940, -27.8577, -17.1852],\n",
       "         [ 10.8309,  -7.1558,  19.4959],\n",
       "         [ 12.8625,  25.4021,  15.1339],\n",
       "         [  4.1456,   8.0469, -28.7858],\n",
       "         [-13.9301,  20.5040,  28.6081],\n",
       "         [ 27.6212,  -2.6840,  20.5943],\n",
       "         [-29.0864, -28.0095, -22.1735],\n",
       "         [ -2.1245, -23.1596,  16.8079],\n",
       "         [ 27.8804,   4.4748, -22.0981],\n",
       "         [ -0.6870,  13.8609, -22.1685]]),\n",
       " tensor([[-16.1160],\n",
       "         [-12.3924],\n",
       "         [ 95.0541],\n",
       "         [ 96.0076],\n",
       "         [ 27.1318],\n",
       "         [ 21.3712],\n",
       "         [-60.2942],\n",
       "         [-71.2829],\n",
       "         [103.6911],\n",
       "         [ 98.8805]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10], y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простой градиентый спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3760.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2012,  2.9850, -1.5039]], requires_grad=True)\n",
      "tensor([[21.7280]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1, n), requires_grad=True)\n",
    "b = torch.randn((1, 1), requires_grad=True)\n",
    "\n",
    "learnin_rate = 1e-3\n",
    "max_epochs = 1000\n",
    "\n",
    "for epoch in tqdm.trange(max_epochs):\n",
    "    y_pred = torch.mm(X_train, a.T) + b\n",
    "    mse = ((y_train - y_pred) ** 2).mean()\n",
    "    \n",
    "    mse.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= learnin_rate * a.grad\n",
    "        b -= learnin_rate * b.grad\n",
    "        \n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "print(a) \n",
    "print(b)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Встроенные оптимизаторы (SGD) и функция потерь (MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3155.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2012,  2.9850, -1.5039]], requires_grad=True)\n",
      "tensor([[21.7226]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1, n), requires_grad=True)\n",
    "b = torch.randn((1, 1), requires_grad=True)\n",
    "\n",
    "optimizer = SGD([a, b], lr=1e-3)\n",
    "loss = MSELoss()\n",
    "\n",
    "max_epochs = 1000\n",
    "for epoch in tqdm.trange(max_epochs):\n",
    "    y_pred = torch.mm(X_train, a.T) + b\n",
    "    mse = loss(y_train, y_pred)\n",
    "    \n",
    "    mse.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()    \n",
    "\n",
    "print(a) \n",
    "print(b)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Батчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 358.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1930,  2.9922, -1.4927]], requires_grad=True)\n",
      "tensor([[25.1076]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1, n), requires_grad=True)\n",
    "b = torch.randn((1, 1), requires_grad=True)\n",
    "\n",
    "optimizer = SGD([a, b], lr=1e-3)\n",
    "loss = MSELoss()\n",
    "\n",
    "max_epochs = 1000\n",
    "batch_size = 30\n",
    "l = len(X_train)\n",
    "for epoch in tqdm.trange(max_epochs):\n",
    "    for batch in range((l + batch_size - 1) // batch_size): \n",
    "        s, e = (batch * batch_size), min((batch + 1) * batch_size, l)\n",
    "        X_batch = X_train[s:e]\n",
    "        \n",
    "        y_pred = torch.mm(X_batch, a.T) + b\n",
    "        mse = loss(y_train[s:e], y_pred)\n",
    "\n",
    "        mse.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "print(a) \n",
    "print(b)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Батчи через Dataset и Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 173.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1930,  2.9922, -1.4927]], requires_grad=True)\n",
      "tensor([[25.1076]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1, n), requires_grad=True)\n",
    "b = torch.randn((1, 1), requires_grad=True)\n",
    "\n",
    "optimizer = SGD([a, b], lr=1e-3)\n",
    "loss = MSELoss()\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=30)\n",
    "\n",
    "max_epochs = 1000\n",
    "for epoch in tqdm.trange(max_epochs):\n",
    "    for X_batch, y_batch in data_loader:                \n",
    "        y_pred = torch.mm(X_batch, a.T) + b\n",
    "        mse = loss(y_batch, y_pred)\n",
    "\n",
    "        mse.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "print(a) \n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расширение nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 158.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1930,  2.9922, -1.4927]])\n",
      "tensor([25.1076])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n=3):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n, 1)\n",
    "                \n",
    "    def forward(self, x):        \n",
    "        return self.linear(x)\n",
    "    \n",
    "\n",
    "model = LinearRegression(n)\n",
    "#model = nn.Sequential(nn.Linear(n, 1))\n",
    "optimizer = SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss = MSELoss()\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=30)\n",
    "\n",
    "max_epochs = 1000\n",
    "for epoch in tqdm.trange(max_epochs):\n",
    "    for X_batch, y_batch in data_loader:   \n",
    "        model.train()\n",
    "        y_pred = model(X_batch)\n",
    "        mse = loss(y_batch, y_pred)\n",
    "\n",
    "        mse.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "print(model.state_dict()['linear.weight'])      \n",
    "print(model.state_dict()['linear.bias'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "Запуск в командной строке:\n",
    "\n",
    "```tensorboard --logdir .```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 77.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1580,  2.9689, -1.5137]])\n",
      "tensor([21.7453])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "model = nn.Sequential(nn.Linear(n, 1))\n",
    "optimizer = SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss = MSELoss()\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=30)\n",
    "\n",
    "max_epochs = 100\n",
    "for epoch in tqdm.trange(max_epochs):\n",
    "    for X_batch, y_batch in train_loader:   \n",
    "        model.train()\n",
    "        y_pred = model(X_batch)\n",
    "        mse = loss(y_batch, y_pred)\n",
    "\n",
    "        mse.backward()        \n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "    if epoch % 3 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_pred = model(X_val)\n",
    "            mse_val = loss(y_val, y_pred)\n",
    "            \n",
    "            stat = { 'mse_validation': mse_val.item(),\n",
    "                     'b': model.state_dict()['0.bias']    \n",
    "            }\n",
    "            writer.add_graph(model, X_val)\n",
    "            writer.add_scalars('training/stat', stat, epoch)\n",
    "            torch.save(model, 'checkpoint')\n",
    "            \n",
    "writer.close()\n",
    "\n",
    "print(model.state_dict()['0.weight'])      \n",
    "print(model.state_dict()['0.bias'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 1,  MSE: 647.15\n",
      "Validation Results - Epoch: 2,  MSE: 621.33\n",
      "Validation Results - Epoch: 3,  MSE: 596.65\n",
      "Validation Results - Epoch: 4,  MSE: 572.93\n",
      "Validation Results - Epoch: 5,  MSE: 550.16\n",
      "Validation Results - Epoch: 6,  MSE: 528.29\n",
      "Validation Results - Epoch: 7,  MSE: 507.28\n",
      "Validation Results - Epoch: 8,  MSE: 487.10\n",
      "Validation Results - Epoch: 9,  MSE: 467.73\n",
      "Validation Results - Epoch: 10,  MSE: 449.12\n",
      "Validation Results - Epoch: 11,  MSE: 431.24\n",
      "Validation Results - Epoch: 12,  MSE: 414.08\n",
      "Validation Results - Epoch: 13,  MSE: 397.59\n",
      "Validation Results - Epoch: 14,  MSE: 381.76\n",
      "Validation Results - Epoch: 15,  MSE: 366.55\n",
      "Validation Results - Epoch: 16,  MSE: 351.95\n",
      "Validation Results - Epoch: 17,  MSE: 337.93\n",
      "Validation Results - Epoch: 18,  MSE: 324.46\n",
      "Validation Results - Epoch: 19,  MSE: 311.53\n",
      "Validation Results - Epoch: 20,  MSE: 299.10\n",
      "Validation Results - Epoch: 21,  MSE: 287.18\n",
      "Validation Results - Epoch: 22,  MSE: 275.72\n",
      "Validation Results - Epoch: 23,  MSE: 264.72\n",
      "Validation Results - Epoch: 24,  MSE: 254.16\n",
      "Validation Results - Epoch: 25,  MSE: 244.01\n",
      "Validation Results - Epoch: 26,  MSE: 234.27\n",
      "Validation Results - Epoch: 27,  MSE: 224.92\n",
      "Validation Results - Epoch: 28,  MSE: 215.93\n",
      "Validation Results - Epoch: 29,  MSE: 207.31\n",
      "Validation Results - Epoch: 30,  MSE: 199.03\n",
      "Validation Results - Epoch: 31,  MSE: 191.07\n",
      "Validation Results - Epoch: 32,  MSE: 183.43\n",
      "Validation Results - Epoch: 33,  MSE: 176.10\n",
      "Validation Results - Epoch: 34,  MSE: 169.06\n",
      "Validation Results - Epoch: 35,  MSE: 162.30\n",
      "Validation Results - Epoch: 36,  MSE: 155.80\n",
      "Validation Results - Epoch: 37,  MSE: 149.57\n",
      "Validation Results - Epoch: 38,  MSE: 143.59\n",
      "Validation Results - Epoch: 39,  MSE: 137.84\n",
      "Validation Results - Epoch: 40,  MSE: 132.32\n",
      "Validation Results - Epoch: 41,  MSE: 127.02\n",
      "Validation Results - Epoch: 42,  MSE: 121.94\n",
      "Validation Results - Epoch: 43,  MSE: 117.05\n",
      "Validation Results - Epoch: 44,  MSE: 112.36\n",
      "Validation Results - Epoch: 45,  MSE: 107.86\n",
      "Validation Results - Epoch: 46,  MSE: 103.54\n",
      "Validation Results - Epoch: 47,  MSE: 99.39\n",
      "Validation Results - Epoch: 48,  MSE: 95.41\n",
      "Validation Results - Epoch: 49,  MSE: 91.58\n",
      "Validation Results - Epoch: 50,  MSE: 87.91\n",
      "Validation Results - Epoch: 51,  MSE: 84.39\n",
      "Validation Results - Epoch: 52,  MSE: 81.00\n",
      "Validation Results - Epoch: 53,  MSE: 77.76\n",
      "Validation Results - Epoch: 54,  MSE: 74.64\n",
      "Validation Results - Epoch: 55,  MSE: 71.65\n",
      "Validation Results - Epoch: 56,  MSE: 68.77\n",
      "Validation Results - Epoch: 57,  MSE: 66.02\n",
      "Validation Results - Epoch: 58,  MSE: 63.37\n",
      "Validation Results - Epoch: 59,  MSE: 60.83\n",
      "Validation Results - Epoch: 60,  MSE: 58.39\n",
      "Validation Results - Epoch: 61,  MSE: 56.05\n",
      "Validation Results - Epoch: 62,  MSE: 53.80\n",
      "Validation Results - Epoch: 63,  MSE: 51.64\n",
      "Validation Results - Epoch: 64,  MSE: 49.58\n",
      "Validation Results - Epoch: 65,  MSE: 47.59\n",
      "Validation Results - Epoch: 66,  MSE: 45.68\n",
      "Validation Results - Epoch: 67,  MSE: 43.85\n",
      "Validation Results - Epoch: 68,  MSE: 42.10\n",
      "Validation Results - Epoch: 69,  MSE: 40.41\n",
      "Validation Results - Epoch: 70,  MSE: 38.80\n",
      "Validation Results - Epoch: 71,  MSE: 37.24\n",
      "Validation Results - Epoch: 72,  MSE: 35.76\n",
      "Validation Results - Epoch: 73,  MSE: 34.33\n",
      "Validation Results - Epoch: 74,  MSE: 32.96\n",
      "Validation Results - Epoch: 75,  MSE: 31.64\n",
      "Validation Results - Epoch: 76,  MSE: 30.38\n",
      "Validation Results - Epoch: 77,  MSE: 29.17\n",
      "Validation Results - Epoch: 78,  MSE: 28.01\n",
      "Validation Results - Epoch: 79,  MSE: 26.89\n",
      "Validation Results - Epoch: 80,  MSE: 25.82\n",
      "Validation Results - Epoch: 81,  MSE: 24.80\n",
      "Validation Results - Epoch: 82,  MSE: 23.81\n",
      "Validation Results - Epoch: 83,  MSE: 22.87\n",
      "Validation Results - Epoch: 84,  MSE: 21.96\n",
      "Validation Results - Epoch: 85,  MSE: 21.09\n",
      "Validation Results - Epoch: 86,  MSE: 20.26\n",
      "Validation Results - Epoch: 87,  MSE: 19.46\n",
      "Validation Results - Epoch: 88,  MSE: 18.70\n",
      "Validation Results - Epoch: 89,  MSE: 17.96\n",
      "Validation Results - Epoch: 90,  MSE: 17.26\n",
      "Validation Results - Epoch: 91,  MSE: 16.58\n",
      "Validation Results - Epoch: 92,  MSE: 15.93\n",
      "Validation Results - Epoch: 93,  MSE: 15.31\n",
      "Validation Results - Epoch: 94,  MSE: 14.71\n",
      "Validation Results - Epoch: 95,  MSE: 14.14\n",
      "Validation Results - Epoch: 96,  MSE: 13.59\n",
      "Validation Results - Epoch: 97,  MSE: 13.07\n",
      "Validation Results - Epoch: 98,  MSE: 12.56\n",
      "Validation Results - Epoch: 99,  MSE: 12.08\n",
      "Validation Results - Epoch: 100,  MSE: 11.62\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import MeanSquaredError\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=30)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=10)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(n, 1))\n",
    "optimizer = SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss = MeanSquaredError()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, F.mse_loss)\n",
    "evaluator = create_supervised_evaluator(model,  metrics={'mse': loss})\n",
    "\n",
    "writer = SummaryWriter()\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    mse = metrics['mse']\n",
    "    writer.add_scalar('training/mse_train', mse, engine.state.epoch)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    mse = metrics['mse']    \n",
    "    print(f'Validation Results - Epoch: {engine.state.epoch},  MSE: {mse:.2f}')                  \n",
    "    writer.add_scalar('training/mse_validation', mse, engine.state.epoch)\n",
    "        \n",
    "trainer.run(train_loader, max_epochs=max_epochs)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
